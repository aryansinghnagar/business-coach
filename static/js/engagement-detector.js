/**
 * Engagement Detection Manager Module
 *
 * Manages engagement detection lifecycle and API communication.
 * Runs in parallel with the insight session: this module uses VIDEO from the feed
 * (visual cues); the insight session uses AUDIO from the same feed (aural cues via
 * feed STT â†’ POST /engagement/transcript). Visual and speech cues are combined for
 * B2B meeting insights; popup messages are generated by Azure OpenAI (see docs/DOCUMENTATION.md).
 *
 * Features:
 * - Start/stop engagement detection (video path)
 * - Poll engagement state from backend
 * - Spike alerts: popup + TTS (insights session, audio-only)
 * - Partner video capture (frames sent to backend); feed audio is handled separately for aural cues
 */

class EngagementDetector {
    /**
     * Initialize the engagement detector.
     * 
     * @param {Object} options - Configuration options
     * @param {string} options.apiBaseUrl - Base URL for API (default: 'http://localhost:5000')
     * @param {number} options.pollInterval - Polling interval in milliseconds (default: 200)
     */
    constructor(options = {}) {
        this.signifierPanel = options.signifierPanel || null;
        this.azureMetricsPanel = options.azureMetricsPanel || null;
        this.apiBaseUrl = options.apiBaseUrl || 'http://localhost:5000';
        this.pollInterval = options.pollInterval || 200;
        this.onAlert = options.onAlert || null;
        this.onPartnerStreamStateChange = options.onPartnerStreamStateChange || null;
        
        // State management
        this.isActive = false;
        this.pollIntervalId = null;
        this.currentSourceType = null;
        this.currentSourcePath = null;
        this.currentDetectionMethod = null;
        
        // Error handling
        this.consecutiveErrors = 0;
        this.maxConsecutiveErrors = 5;
        
        // Request throttling
        this._pendingRequest = false;
        
        // Partner (Meeting Partner Video) capture: stream + frame-send loop
        this._partnerStream = null;
        this._partnerFrameIntervalId = null;
        this._partnerVideo = null;
        this._partnerCanvas = null;
    }
    
    /**
     * Start engagement detection.
     * 
     * @param {string} sourceType - Video source type ('webcam', 'file', 'stream', 'partner')
     * @param {string|null} sourcePath - Path to video file or stream URL (required for 'file'/'stream')
     * @param {string|null} detectionMethod - Ignored; app chooses optimal method (auto)
     * @returns {Promise<boolean>} True if started successfully
     */
    async start(sourceType = 'webcam', sourcePath = null, detectionMethod = null) {
        try {
            const response = await fetch(`${this.apiBaseUrl}/engagement/start`, {
                method: 'POST',
                headers: {
                    'Content-Type': 'application/json'
                },
                body: JSON.stringify({
                    sourceType: sourceType,
                    sourcePath: sourcePath
                })
            });
            
            if (!response.ok) {
                let errMsg = response.statusText || 'Failed to start';
                try {
                    const err = await response.json();
                    if (err && (err.error || err.details)) errMsg = err.error || err.details;
                } catch (_) {}
                console.error('Failed to start engagement detection:', errMsg);
                return false;
            }
            
            const result = await response.json();
            console.log('Engagement detection started:', result.message);
            
            // Store current configuration
            this.currentSourceType = sourceType;
            this.currentSourcePath = sourcePath;
            this.currentDetectionMethod = result.detectionMethod || detectionMethod;
            this._setMetricsPanelVisibility(this.currentDetectionMethod || 'mediapipe');

            // Start polling
            this.isActive = true;
            this.consecutiveErrors = 0;
            this.startPolling();
            
            return true;
        } catch (error) {
            console.error('Error starting engagement detection:', error);
            return false;
        }
    }
    
    /**
     * Stop engagement detection.
     * 
     * @returns {Promise<boolean>} True if stopped successfully
     */
    async stop() {
        try {
            const response = await fetch(`${this.apiBaseUrl}/engagement/stop`, {
                method: 'POST'
            });
            
            if (!response.ok) {
                try {
                    const err = await response.json().catch(() => ({}));
                    console.error('Failed to stop engagement detection:', err.error || err.details || response.statusText);
                } catch (_) {
                    console.error('Failed to stop engagement detection:', response.statusText);
                }
                return false;
            }
            
            // Stop polling
            this.isActive = false;
            this.stopPolling();
            this.stopPartnerFrameStream();
            
            if (this.signifierPanel) {
                this.signifierPanel.reset();
            }
            if (this.azureMetricsPanel) {
                this.azureMetricsPanel.reset();
            }
            var hintEl = document.getElementById('engagementMetricsHint');
            if (hintEl) hintEl.style.display = 'none';
            this._setMetricsPanelVisibility('mediapipe');
            
            // Clear state
            this.currentSourceType = null;
            this.currentSourcePath = null;
            this.currentDetectionMethod = null;
            this.consecutiveErrors = 0;
            
            return true;
        } catch (error) {
            console.error('Error stopping engagement detection:', error);
            return false;
        }
    }
    
    /**
     * Start polling for engagement state updates.
     */
    startPolling() {
        if (this.pollIntervalId) {
            clearInterval(this.pollIntervalId);
        }
        
        // Poll immediately, then at intervals
        this.pollEngagementState();
        this.pollIntervalId = setInterval(() => {
            this.pollEngagementState();
        }, this.pollInterval);
    }
    
    /**
     * Stop polling for engagement state updates.
     */
    stopPolling() {
        if (this.pollIntervalId) {
            clearInterval(this.pollIntervalId);
            this.pollIntervalId = null;
        }
    }
    
    /**
     * Poll the backend for current engagement state.
     * Uses request throttling to avoid excessive requests during rapid updates.
     */
    async pollEngagementState() {
        if (!this.isActive) {
            return;
        }
        
        // Throttle: skip if previous request is still pending
        if (this._pendingRequest) {
            return;
        }
        
        try {
            this._pendingRequest = true;
            // Add timestamp to prevent caching
            const response = await fetch(`${this.apiBaseUrl}/engagement/state?t=${Date.now()}`, {
                method: 'GET',
                cache: 'no-cache',
                headers: {
                    'Cache-Control': 'no-cache'
                }
            });
            
            if (!response.ok) {
                if (response.status === 404) {
                    // Detection not started yet - not an error
                    return;
                }
                throw new Error(`HTTP ${response.status}`);
            }
            
            const data = await response.json();
            
            this.consecutiveErrors = 0;
            
            // Show MediaPipe or Azure metrics panel based on detection method
            var method = (data.detectionMethod && data.detectionMethod.toLowerCase()) || 'mediapipe';
            this._setMetricsPanelVisibility(method);

            this._updateMetricsHint(data.faceDetected, data.signifierScores, data.azureMetrics);

            if (method === 'azure_face_api') {
                if (this.azureMetricsPanel) {
                    if (data.faceDetected === false) {
                        this.azureMetricsPanel.reset();
                    } else if (data.azureMetrics != null) {
                        this.azureMetricsPanel.update(data.azureMetrics);
                    }
                }
            } else {
                if (this.signifierPanel) {
                    if (data.faceDetected === false) {
                        this.signifierPanel.reset();
                    } else if (data.signifierScores != null) {
                        this.signifierPanel.update(data.signifierScores);
                    }
                }
            }

            // Metric spike alert: show popup (and optionally speak via avatar)
            if (data.alert && data.alert.message && typeof this.onAlert === 'function') {
                this.onAlert(data.alert);
            }
            
        } catch (error) {
            this.consecutiveErrors++;
            console.debug('Engagement state fetch error:', error);
            
            // Stop polling after too many consecutive errors
            if (this.consecutiveErrors >= this.maxConsecutiveErrors) {
                console.warn('Too many consecutive errors, stopping engagement detection polling');
                this.stopPolling();
                this.isActive = false;
            }
        } finally {
            this._pendingRequest = false;
        }
    }
    
    /**
     * Update the metrics hint when engagement is active but no face/metrics available.
     */
    _updateMetricsHint(faceDetected, signifierScores, azureMetrics) {
        var hintEl = document.getElementById('engagementMetricsHint');
        if (!hintEl) return;
        var hasData = (signifierScores && Object.keys(signifierScores).length > 0) ||
            (azureMetrics && (azureMetrics.base || azureMetrics.composite));
        if (hasData) {
            hintEl.style.display = 'none';
        } else if (faceDetected === false) {
            hintEl.textContent = 'Position your face in view to see engagement metrics';
            hintEl.style.display = 'block';
        }
    }

    /**
     * Show signifier panel (MediaPipe) or Azure metrics panel based on resolved detection method.
     * @param {string} detectionMethod - Resolved method from backend ('mediapipe' | 'azure_face_api' | 'unified')
     */
    _setMetricsPanelVisibility(detectionMethod) {
        var sigEl = document.getElementById('signifierPanelContainer');
        var azureEl = document.getElementById('azureMetricsPanelContainer');
        if (!sigEl || !azureEl) return;
        var isAzure = (detectionMethod && detectionMethod.toLowerCase() === 'azure_face_api');
        sigEl.style.display = isAzure ? 'none' : 'flex';
        azureEl.style.display = isAzure ? 'flex' : 'none';
    }

    /**
     * Start capturing from a display MediaStream and sending frames to the backend.
     * Call this after start('partner') when the user has chosen a tab/window via getDisplayMedia.
     * 
     * @param {MediaStream} stream - Stream from navigator.mediaDevices.getDisplayMedia()
     */
    startPartnerFrameStream(stream) {
        this.stopPartnerFrameStream();
        this._partnerStream = stream;
        
        const video = document.createElement('video');
        video.autoplay = true;
        video.muted = true;
        video.playsInline = true;
        video.setAttribute('playsinline', '');
        video.srcObject = stream;
        this._partnerVideo = video;
        
        const canvas = document.createElement('canvas');
        const ctx = canvas.getContext('2d');
        this._partnerCanvas = canvas;
        
        const maxWidth = 1280;
        const apiBase = (this.apiBaseUrl || '').replace(/\/$/, '');
        
        const sendFrame = () => {
            if (!this._partnerVideo || !this._partnerStream || !this.isActive) return;
            const v = this._partnerVideo;
            if (v.readyState < 2 || v.videoWidth === 0 || v.videoHeight === 0) return;
            let w = v.videoWidth, h = v.videoHeight;
            if (w > maxWidth) {
                h = Math.round((h * maxWidth) / w);
                w = maxWidth;
            }
            if (canvas.width !== w || canvas.height !== h) {
                canvas.width = w;
                canvas.height = h;
            }
            try {
                ctx.drawImage(v, 0, 0, v.videoWidth, v.videoHeight, 0, 0, w, h);
            } catch (drawErr) {
                return;
            }
            try {
                canvas.toBlob((blob) => {
                    if (!blob || !this.isActive) return;
                    const url = apiBase ? `${apiBase}/engagement/partner-frame` : '/engagement/partner-frame';
                    fetch(url, {
                        method: 'POST',
                        body: blob,
                        headers: { 'Content-Type': 'image/jpeg' }
                    }).catch((fetchErr) => {
                        console.warn('Partner frame upload failed:', fetchErr);
                    });
                }, 'image/jpeg', 0.75);
            } catch (toBlobErr) {
                if (toBlobErr.name === 'SecurityError' || (toBlobErr.message && toBlobErr.message.indexOf('tainted') !== -1)) {
                    console.warn('Partner video: canvas tainted (cannot export). Try sharing a different tab or window.');
                }
            }
        };
        
        let sendLoopStarted = false;
        const startSending = () => {
            if (sendLoopStarted || !this._partnerStream || !this.isActive) return;
            if (video.videoWidth === 0 || video.videoHeight === 0) {
                setTimeout(startSending, 50);
                return;
            }
            sendLoopStarted = true;
            sendFrame();
            this._partnerFrameIntervalId = setInterval(sendFrame, 120);  // ~8 fps, lighter load
            if (typeof this.onPartnerStreamStateChange === 'function') {
                this.onPartnerStreamStateChange(true);
            }
        };
        
        video.addEventListener('loadeddata', startSending, { once: true });
        video.addEventListener('error', (e) => {
            console.warn('Partner video element error:', e);
            this.stopPartnerFrameStream();
        });
        
        video.play().then(() => {
            if (video.videoWidth > 0 && video.videoHeight > 0) {
                startSending();
            }
        }).catch((err) => {
            console.warn('Partner video play failed:', err);
            this.stopPartnerFrameStream();
        });
        
        stream.getTracks().forEach((track) => {
            track.onended = () => {
                this.stopPartnerFrameStream();
            };
        });
    }
    
    /**
     * Stop partner frame capture and release display media tracks.
     */
    stopPartnerFrameStream() {
        const hadStream = !!this._partnerStream;
        if (this._partnerFrameIntervalId) {
            clearInterval(this._partnerFrameIntervalId);
            this._partnerFrameIntervalId = null;
        }
        if (this._partnerStream) {
            this._partnerStream.getTracks().forEach((t) => t.stop());
            this._partnerStream = null;
        }
        this._partnerVideo = null;
        this._partnerCanvas = null;
        if (hadStream && typeof this.onPartnerStreamStateChange === 'function') {
            this.onPartnerStreamStateChange(false);
        }
    }
    
    /**
     * Whether the Meeting Partner Video capture (getDisplayMedia) is currently active.
     * @returns {boolean}
     */
    isPartnerStreamActive() {
        return !!this._partnerStream;
    }
    
    /**
     * Get current detection status.
     * 
     * @returns {Object} Status information
     */
    getStatus() {
        return {
            isActive: this.isActive,
            sourceType: this.currentSourceType,
            sourcePath: this.currentSourcePath,
            detectionMethod: this.currentDetectionMethod,
            consecutiveErrors: this.consecutiveErrors
        };
    }
}

// Export for use in other modules
if (typeof module !== 'undefined' && module.exports) {
    module.exports = EngagementDetector;
}
