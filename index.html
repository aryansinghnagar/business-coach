<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Business Meeting Copilot</title>
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&display=swap" rel="stylesheet">
    
    <script>
        /**
         * WebRTC polyfill for RTCPeerConnection.getConfiguration (required for avatar audio).
         * Applied before and after SDK load to ensure compatibility.
         */
        (function applyWebRTCPolyfill() {
            if (typeof RTCPeerConnection === 'undefined') return;
            
            const getConfigImpl = function() {
                return { iceServers: [], iceTransportPolicy: 'all', bundlePolicy: 'balanced' };
            };
            
            const applyPolyfill = function() {
                if (typeof RTCPeerConnection.prototype.getConfiguration !== 'function') {
                    RTCPeerConnection.prototype.getConfiguration = getConfigImpl;
                }
            };
            
            // Apply immediately
            applyPolyfill();
            
            // Proxy constructor to apply to new instances
            const OriginalRTC = window.RTCPeerConnection;
            window.RTCPeerConnection = new Proxy(OriginalRTC, {
                construct: function(target, args) {
                    const pc = new target(...args);
                    applyPolyfill.call(pc);
                    return pc;
                },
                get: function(target, prop) {
                    return target[prop];
                }
            });
        })();
    </script>
    <script src="https://aka.ms/csspeech/jsbrowserpackageraw"></script>
    <script>
        // Re-apply WebRTC polyfill after SDK loads (SDK may override prototype)
        (function() {
            if (typeof RTCPeerConnection === 'undefined') return;
            if (typeof RTCPeerConnection.prototype.getConfiguration !== 'function') {
                RTCPeerConnection.prototype.getConfiguration = function() {
                    return { iceServers: [], iceTransportPolicy: 'all', bundlePolicy: 'balanced' };
                };
            }
        })();
    </script>
    
    <style>
        * { 
            margin: 0; 
            padding: 0; 
            box-sizing: border-box; 
        }
        
        body {
            font-family: 'Inter', -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, 'Helvetica Neue', Arial, sans-serif;
            background: linear-gradient(135deg, #667eea 0%, #764ba2 50%, #f093fb 100%);
            background-attachment: fixed;
            color: #fff;
            margin: 0;
            padding: 0;
            min-height: 100vh;
            position: relative;
            overflow: hidden;
        }
        
        body::before {
            content: '';
            position: fixed;
            top: 0;
            left: 0;
            right: 0;
            bottom: 0;
            background: 
                radial-gradient(circle at 20% 50%, rgba(120, 119, 198, 0.3) 0%, transparent 50%),
                radial-gradient(circle at 80% 80%, rgba(255, 119, 198, 0.3) 0%, transparent 50%);
            pointer-events: none;
            z-index: 0;
        }
        
        .main-container {
            display: flex;
            height: 100vh;
            position: relative;
            z-index: 1;
            overflow: hidden;
        }
        
        /* Sidebar (single-column layout: video feed and all controls in sidebar) */
        .sidebar {
            flex: 1;
            width: 100%;
            max-width: 480px;
            min-width: 320px;
            background: linear-gradient(180deg, rgba(15, 23, 42, 0.97) 0%, rgba(30, 27, 75, 0.95) 100%);
            backdrop-filter: blur(20px);
            border-right: 1px solid rgba(167, 139, 250, 0.12);
            display: flex;
            flex-direction: column;
            overflow: hidden;
            box-shadow: 4px 0 32px rgba(0, 0, 0, 0.25);
        }
        
        .sidebar-header {
            padding: 20px 24px;
            border-bottom: 1px solid rgba(167, 139, 250, 0.15);
            background: linear-gradient(135deg, rgba(102, 126, 234, 0.2) 0%, rgba(167, 139, 250, 0.12) 100%);
        }
        
        .sidebar-header h1 {
            font-size: 1.5rem;
            font-weight: 700;
            margin: 0;
            background: linear-gradient(135deg, #ffffff 0%, #c4b5fd 50%, #e0e7ff 100%);
            -webkit-background-clip: text;
            -webkit-text-fill-color: transparent;
            background-clip: text;
            letter-spacing: -0.02em;
        }
        
        .sidebar-header .status-indicator {
            margin-top: 8px;
            padding: 8px 12px;
            background: rgba(255, 255, 255, 0.06);
            backdrop-filter: blur(10px);
            border-radius: 8px;
            font-size: 0.8rem;
            color: rgba(255, 255, 255, 0.88);
            border: 1px solid rgba(167, 139, 250, 0.2);
            font-weight: 400;
        }
        
        .sidebar-content {
            flex: 1;
            overflow-y: auto;
            overflow-x: hidden;
            padding: 18px 20px 24px 20px;
            display: flex;
            flex-direction: column;
            gap: 18px;
        }
        
        .sidebar-content::-webkit-scrollbar {
            width: 8px;
        }
        
        .sidebar-content::-webkit-scrollbar-track {
            background: rgba(255, 255, 255, 0.04);
            border-radius: 4px;
        }
        
        .sidebar-content::-webkit-scrollbar-thumb {
            background: rgba(167, 139, 250, 0.35);
            border-radius: 4px;
        }
        
        .sidebar-content::-webkit-scrollbar-thumb:hover {
            background: rgba(167, 139, 250, 0.5);
        }
        
        .sidebar-section {
            background: rgba(255, 255, 255, 0.04);
            backdrop-filter: blur(12px);
            border-radius: 14px;
            padding: 16px;
            border: 1px solid rgba(167, 139, 250, 0.1);
            box-shadow: 0 2px 12px rgba(0, 0, 0, 0.08);
        }
        
        .sidebar-section-title {
            font-size: 0.82rem;
            font-weight: 700;
            text-transform: uppercase;
            letter-spacing: 0.06em;
            color: rgba(255, 255, 255, 0.92);
            margin-bottom: 12px;
            padding-bottom: 8px;
            border-bottom: 1px solid rgba(167, 139, 250, 0.15);
        }
        
        .controls-header {
            display: flex;
            align-items: center;
            justify-content: space-between;
            margin-bottom: 12px;
            padding-bottom: 8px;
            border-bottom: 1px solid rgba(167, 139, 250, 0.15);
        }
        .controls-header .sidebar-section-title {
            margin-bottom: 0;
            padding-bottom: 0;
            border-bottom: none;
        }
        .session-status {
            font-size: 0.75rem;
            font-weight: 600;
            padding: 4px 10px;
            border-radius: 999px;
            letter-spacing: 0.02em;
        }
        .session-status-idle {
            color: rgba(255, 255, 255, 0.65);
            background: rgba(255, 255, 255, 0.08);
            border: 1px solid rgba(255, 255, 255, 0.12);
        }
        .session-status-live {
            color: #22c55e;
            background: rgba(34, 197, 94, 0.15);
            border: 1px solid rgba(34, 197, 94, 0.35);
        }
        
        .button-group {
            display: flex;
            flex-direction: column;
            gap: 8px;
        }
        
        button {
            padding: 14px 28px;
            border-radius: 12px;
            border: none;
            cursor: pointer;
            font-weight: 600;
            font-size: 0.95rem;
            font-family: 'Inter', sans-serif;
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            color: white;
            transition: all 0.3s cubic-bezier(0.4, 0, 0.2, 1);
            box-shadow: 0 4px 14px rgba(102, 126, 234, 0.4);
            position: relative;
            overflow: hidden;
        }
        
        button::before {
            content: '';
            position: absolute;
            top: 0;
            left: -100%;
            width: 100%;
            height: 100%;
            background: linear-gradient(90deg, transparent, rgba(255, 255, 255, 0.2), transparent);
            transition: left 0.5s;
        }
        
        button:hover:not(:disabled)::before {
            left: 100%;
        }
        
        button:hover:not(:disabled) {
            transform: translateY(-2px);
            box-shadow: 0 6px 20px rgba(102, 126, 234, 0.5);
        }
        
        button:active:not(:disabled) {
            transform: translateY(0);
            box-shadow: 0 2px 10px rgba(102, 126, 234, 0.4);
        }
        
        button:disabled {
            opacity: 0.5;
            cursor: not-allowed;
            box-shadow: none;
            transform: none;
        }
        
        button.secondary {
            background: rgba(255, 255, 255, 0.15);
            backdrop-filter: blur(10px);
            border: 1px solid rgba(255, 255, 255, 0.2);
            box-shadow: 0 4px 14px rgba(0, 0, 0, 0.1);
        }
        
        button.secondary:hover:not(:disabled) {
            background: rgba(255, 255, 255, 0.2);
            box-shadow: 0 6px 20px rgba(0, 0, 0, 0.15);
        }
        
        button.danger {
            background: linear-gradient(135deg, #ef4444 0%, #dc2626 100%);
            box-shadow: 0 4px 14px rgba(239, 68, 68, 0.4);
        }
        
        button.danger:hover:not(:disabled) {
            box-shadow: 0 6px 20px rgba(239, 68, 68, 0.5);
        }
        
        /* Video feed inside sidebar */
        .sidebar-section.video-feed-section {
            padding: 0;
            overflow: hidden;
        }
        
        .sidebar-video-wrap {
            position: relative;
            width: 100%;
            aspect-ratio: 16/9;
            max-height: 280px;
            background: linear-gradient(135deg, #1e293b 0%, #0f172a 100%);
            border-radius: 12px;
            overflow: hidden;
            border: 1px solid rgba(255, 255, 255, 0.1);
            box-shadow: 0 4px 16px rgba(0, 0, 0, 0.3);
        }
        
        .sidebar-video-wrap .engagement-feed-wrap {
            position: absolute;
            inset: 0;
            z-index: 0;
        }
        
        .sidebar-video-wrap .engagement-feed {
            width: 100%;
            height: 100%;
            object-fit: cover;
            display: block;
        }
        
        .sidebar-video-wrap .avatar-pip {
            position: absolute;
            bottom: 8px;
            right: 8px;
            width: 28%;
            min-width: 80px;
            max-width: 120px;
            aspect-ratio: 16/9;
            z-index: 5;
            border-radius: 8px;
            overflow: hidden;
            box-shadow: 0 2px 12px rgba(0, 0, 0, 0.5);
            border: 1px solid rgba(255, 255, 255, 0.15);
        }
        
        .sidebar-video-wrap .avatar-pip video,
        .sidebar-video-wrap .avatar-pip audio {
            width: 100%;
            height: 100%;
            object-fit: cover;
            display: block;
        }
        
        .sidebar-video-wrap #subtitles {
            position: absolute;
            bottom: 6%;
            left: 4%;
            right: 4%;
            width: auto;
            font-size: 0.75rem;
            padding: 8px 12px;
            z-index: 999;
        }
        
        /* Metric spike toast (popup when a metric group spikes) */
        .metric-spike-toast {
            position: fixed;
            bottom: 24px;
            left: 50%;
            transform: translateX(-50%);
            max-width: 420px;
            padding: 14px 18px;
            background: linear-gradient(135deg, rgba(30, 27, 75, 0.98) 0%, rgba(15, 23, 42, 0.98) 100%);
            border: 1px solid rgba(167, 139, 250, 0.4);
            border-radius: 12px;
            box-shadow: 0 8px 32px rgba(0, 0, 0, 0.4);
            color: rgba(255, 255, 255, 0.95);
            font-size: 0.9rem;
            line-height: 1.4;
            z-index: 10000;
            animation: toastIn 0.25s ease;
        }
        .metric-spike-toast.hiding {
            animation: toastOut 0.2s ease forwards;
        }
        /* Insight transcript box: scrollable log of insight responses */
        .insight-transcript-section {
            flex: 0 0 auto;
            max-height: 200px;
            min-height: 80px;
        }
        .insight-transcript-box {
            font-size: 0.8rem;
            line-height: 1.35;
            color: rgba(255, 255, 255, 0.9);
            background: rgba(0, 0, 0, 0.2);
            border-radius: 8px;
            padding: 10px 12px;
            max-height: 160px;
            overflow-y: auto;
            white-space: pre-wrap;
            word-break: break-word;
        }
        .insight-transcript-box::-webkit-scrollbar {
            width: 6px;
        }
        .insight-transcript-box::-webkit-scrollbar-thumb {
            background: rgba(167, 139, 250, 0.35);
            border-radius: 3px;
        }
        .insight-entry {
            margin-bottom: 10px;
            padding-bottom: 8px;
            border-bottom: 1px solid rgba(167, 139, 250, 0.15);
        }
        .insight-entry:last-child { border-bottom: none; margin-bottom: 0; }
        .insight-entry .insight-time { color: rgba(255, 255, 255, 0.55); font-size: 0.7rem; }
        @keyframes toastIn {
            from { opacity: 0; transform: translateX(-50%) translateY(12px); }
            to { opacity: 1; transform: translateX(-50%) translateY(0); }
        }
        @keyframes toastOut {
            from { opacity: 1; transform: translateX(-50%) translateY(0); }
            to { opacity: 0; transform: translateX(-50%) translateY(-8px); }
        }

        /* Engagement Metrics Panel (MediaPipe 30 signifiers or Azure emotions + composites) */
        .sidebar-section.engagement-signifiers-panel {
            flex: 0 0 auto;
            height: 380px;
            min-height: 280px;
            display: flex;
            flex-direction: column;
            overflow: hidden;
            padding: 0;
        }
        .engagement-metrics-hint {
            flex: 0 0 auto;
            font-size: 0.75rem;
            color: rgba(167, 139, 250, 0.9);
            padding: 6px 16px 8px 16px;
            background: rgba(167, 139, 250, 0.08);
        }
        .sidebar-section.engagement-signifiers-panel .engagement-metrics-title {
            flex: 0 0 auto;
            font-size: 0.85rem;
            font-weight: 700;
            text-transform: uppercase;
            letter-spacing: 0.06em;
            color: rgba(255, 255, 255, 0.95);
            padding: 14px 16px 10px 16px;
            margin: 0;
            border-bottom: 1px solid rgba(255, 255, 255, 0.12);
            background: rgba(255, 255, 255, 0.03);
        }
        #signifierPanelContainer,
        #azureMetricsPanelContainer.metrics-panel-container {
            flex: 1;
            min-height: 0;
            overflow: hidden;
            display: flex;
            flex-direction: column;
        }
        .signifier-panel-inner {
            display: flex;
            flex-direction: column;
            flex: 1;
            min-height: 0;
            overflow: hidden;
            padding: 12px 16px 16px 16px;
        }
        .azure-metrics-panel-inner {
            padding: 12px 16px 16px 16px;
        }
        .signifier-panel-header {
            font-size: 0.78rem;
            font-weight: 600;
            color: rgba(255, 255, 255, 0.9);
            margin-bottom: 10px;
            letter-spacing: 0.02em;
            display: none;
        }
        .azure-metrics-panel-inner .signifier-panel-header {
            display: block;
            color: rgba(167, 139, 250, 0.95);
        }
        .signifier-panel-groups {
            flex: 1;
            min-height: 0;
            overflow-y: auto;
            overflow-x: hidden;
            display: flex;
            flex-direction: column;
            gap: 14px;
        }
        .signifier-panel-groups::-webkit-scrollbar {
            width: 6px;
        }
        .signifier-panel-groups::-webkit-scrollbar-track {
            background: rgba(255, 255, 255, 0.04);
            border-radius: 3px;
        }
        .signifier-panel-groups::-webkit-scrollbar-thumb {
            background: rgba(167, 139, 250, 0.35);
            border-radius: 3px;
        }
        .signifier-panel-groups::-webkit-scrollbar-thumb:hover {
            background: rgba(167, 139, 250, 0.5);
        }
        .signifier-group {
            background: linear-gradient(135deg, rgba(30, 27, 75, 0.5) 0%, rgba(15, 23, 42, 0.6) 100%);
            border-radius: 10px;
            padding: 12px 14px;
            border: 1px solid rgba(167, 139, 250, 0.15);
            box-shadow: 0 2px 8px rgba(0, 0, 0, 0.15);
        }
        .signifier-group-title {
            font-size: 0.72rem;
            font-weight: 700;
            text-transform: uppercase;
            letter-spacing: 0.06em;
            color: rgba(167, 139, 250, 0.9);
            margin-bottom: 8px;
            padding-bottom: 6px;
            border-bottom: 1px solid rgba(167, 139, 250, 0.2);
        }
        .signifier-list {
            display: flex;
            flex-direction: column;
            gap: 6px;
        }
        .signifier-row {
            display: flex;
            align-items: center;
            gap: 10px;
            font-size: 0.75rem;
        }
        .signifier-label {
            flex: 0 0 115px;
            color: rgba(255, 255, 255, 0.92);
            white-space: nowrap;
            overflow: hidden;
            text-overflow: ellipsis;
        }
        .signifier-bar {
            flex: 1;
            min-width: 48px;
            height: 6px;
            background: rgba(0, 0, 0, 0.35);
            border-radius: 4px;
            overflow: hidden;
        }
        .signifier-bar-fill {
            height: 100%;
            width: 0%;
            border-radius: 4px;
            transition: width 0.35s ease-out, background 0.25s ease;
        }
        .signifier-value {
            flex: 0 0 36px;
            text-align: right;
            font-weight: 600;
            color: rgba(255, 255, 255, 0.98);
            font-variant-numeric: tabular-nums;
            font-size: 0.75rem;
        }
        
        /* Video Source Selector Modal Styles */
        .video-source-modal {
            position: fixed;
            top: 0;
            left: 0;
            right: 0;
            bottom: 0;
            z-index: 10000;
            display: flex;
            align-items: center;
            justify-content: center;
            opacity: 0;
            pointer-events: none;
            transition: opacity 0.3s ease;
        }
        
        .video-source-modal.active {
            opacity: 1;
            pointer-events: all;
        }
        
        .video-source-modal-overlay {
            position: absolute;
            top: 0;
            left: 0;
            right: 0;
            bottom: 0;
            background: rgba(0, 0, 0, 0.7);
            backdrop-filter: blur(8px);
        }
        
        .video-source-modal-content {
            position: relative;
            background: rgba(15, 23, 42, 0.95);
            backdrop-filter: blur(20px);
            border-radius: 24px;
            padding: 32px;
            max-width: 600px;
            width: 90%;
            max-height: 90vh;
            overflow-y: auto;
            box-shadow: 
                0 20px 60px rgba(0, 0, 0, 0.3),
                0 0 0 1px rgba(255, 255, 255, 0.1);
            transform: scale(0.95);
            transition: transform 0.3s ease;
        }
        
        .video-source-modal.active .video-source-modal-content {
            transform: scale(1);
        }
        
        .video-source-modal-header {
            margin-bottom: 24px;
            text-align: center;
        }
        
        .video-source-modal-header h2 {
            font-size: 1.5rem;
            font-weight: 700;
            margin-bottom: 8px;
            color: #fff;
        }
        
        .video-source-modal-header p {
            font-size: 0.9rem;
            color: rgba(255, 255, 255, 0.7);
        }
        
        .video-source-options {
            display: flex;
            flex-direction: column;
            gap: 12px;
            margin-bottom: 24px;
        }
        
        .video-source-option {
            display: flex;
            align-items: center;
            gap: 16px;
            padding: 16px;
            background: rgba(255, 255, 255, 0.05);
            border: 2px solid rgba(255, 255, 255, 0.1);
            border-radius: 12px;
            cursor: pointer;
            transition: all 0.2s ease;
        }
        
        .video-source-option:hover {
            background: rgba(255, 255, 255, 0.1);
            border-color: rgba(255, 255, 255, 0.2);
            transform: translateY(-2px);
        }
        
        .video-source-option input[type="radio"]:checked + label ~ *,
        .video-source-option:has(input[type="radio"]:checked) {
            background: rgba(99, 102, 241, 0.2);
            border-color: rgba(99, 102, 241, 0.5);
        }
        
        .video-source-icon {
            font-size: 2rem;
            flex-shrink: 0;
        }
        
        .video-source-info {
            flex: 1;
        }
        
        .video-source-info h3 {
            font-size: 1rem;
            font-weight: 600;
            margin-bottom: 4px;
            color: #fff;
        }
        
        .video-source-info p {
            font-size: 0.85rem;
            color: rgba(255, 255, 255, 0.6);
        }
        
        .video-source-radio {
            flex-shrink: 0;
        }
        
        .video-source-radio input[type="radio"] {
            width: 20px;
            height: 20px;
            cursor: pointer;
            accent-color: #6366f1;
        }
        
        .video-source-file-input {
            margin-bottom: 24px;
            padding: 16px;
            background: rgba(255, 255, 255, 0.05);
            border-radius: 12px;
            border: 2px dashed rgba(255, 255, 255, 0.2);
        }
        
        .file-input-label {
            display: flex;
            align-items: center;
            gap: 12px;
            cursor: pointer;
        }
        
        .file-input-button {
            padding: 10px 20px;
            background: rgba(99, 102, 241, 0.2);
            border: 1px solid rgba(99, 102, 241, 0.5);
            border-radius: 8px;
            color: #fff;
            font-weight: 500;
            transition: all 0.2s ease;
        }
        
        .file-input-button:hover {
            background: rgba(99, 102, 241, 0.3);
            border-color: rgba(99, 102, 241, 0.7);
        }
        
        .file-input-text {
            color: #9ca3af;
            font-size: 0.9rem;
        }
        
        .file-input-hint {
            margin-top: 8px;
            font-size: 0.75rem;
            color: rgba(255, 255, 255, 0.5);
        }
        
        .video-source-modal-footer {
            display: flex;
            gap: 12px;
            justify-content: flex-end;
        }
        
        .btn-cancel,
        .btn-confirm {
            padding: 12px 24px;
            border-radius: 8px;
            font-weight: 600;
            cursor: pointer;
            transition: all 0.2s ease;
            border: none;
            font-size: 0.9rem;
        }
        
        .btn-cancel {
            background: rgba(255, 255, 255, 0.1);
            color: rgba(255, 255, 255, 0.8);
        }
        
        .btn-cancel:hover {
            background: rgba(255, 255, 255, 0.2);
        }
        
        .btn-confirm {
            background: linear-gradient(135deg, #6366f1 0%, #8b5cf6 100%);
            color: #fff;
        }
        
        .btn-confirm:hover {
            transform: translateY(-2px);
            box-shadow: 0 4px 12px rgba(99, 102, 241, 0.4);
        }
        
        /* Video container: in sidebar it uses aspect-ratio and max-height */
        #remoteVideo.sidebar-video-wrap {
            width: 100%;
            height: auto;
            max-height: 280px;
            aspect-ratio: 16/9;
        }
        
        #remoteVideo:hover {
            transform: none;
        }
        
        #remoteVideo.sidebar-video-wrap:hover {
            box-shadow: 0 6px 20px rgba(0, 0, 0, 0.4);
        }
        
        .engagement-feed-wrap {
            position: absolute;
            inset: 0;
            z-index: 0;
        }
        
        .engagement-feed {
            width: 100%;
            height: 100%;
            object-fit: cover;
            display: block;
        }
        
        .avatar-pip {
            position: absolute;
            bottom: 12px;
            right: 12px;
            width: 22%;
            min-width: 140px;
            max-width: 200px;
            aspect-ratio: 16/9;
            z-index: 5;
            border-radius: 12px;
            overflow: hidden;
            box-shadow: 0 4px 20px rgba(0, 0, 0, 0.5);
            border: 2px solid rgba(255, 255, 255, 0.15);
        }
        
        .avatar-pip video,
        .avatar-pip audio {
            width: 100%;
            height: 100%;
            object-fit: cover;
            display: block;
        }
        
        #remoteVideo video {
            width: 100%;
            height: 100%;
            object-fit: cover;
            display: block;
        }
        
        #subtitles {
            width: 90%;
            text-align: center;
            color: white;
            text-shadow: 
                -1px -1px 2px rgba(0, 0, 0, 0.8),
                1px -1px 2px rgba(0, 0, 0, 0.8),
                -1px 1px 2px rgba(0, 0, 0, 0.8),
                1px 1px 2px rgba(0, 0, 0, 0.8);
            position: absolute;
            bottom: 8%;
            left: 5%;
            z-index: 999;
            font-size: 1.15rem;
            font-weight: 600;
            padding: 14px 24px;
            background: rgba(0, 0, 0, 0.7);
            backdrop-filter: blur(10px);
            border-radius: 12px;
            border: 1px solid rgba(255, 255, 255, 0.1);
            box-shadow: 0 4px 16px rgba(0, 0, 0, 0.3);
            transition: opacity 0.3s ease;
        }
        
        /* Smooth animations */
        @keyframes fadeIn {
            from {
                opacity: 0;
                transform: translateY(10px);
            }
            to {
                opacity: 1;
                transform: translateY(0);
            }
        }
        
        .chat-container {
            animation: fadeIn 0.5s ease-out;
        }
        
        /* Improved button icons */
        button svg {
            transition: transform 0.3s ease;
        }
        
        button:hover:not(:disabled) svg {
            transform: scale(1.1);
        }
        
        /* Better focus states */
        *:focus-visible {
            outline: 2px solid rgba(102, 126, 234, 0.6);
            outline-offset: 2px;
            border-radius: 4px;
        }
        
        /* Panel mode: app embedded in extension side panel on any webpage */
        body.panel-mode .main-container {
            width: 100%;
            max-width: none;
        }
        body.panel-mode .sidebar {
            max-width: none;
            width: 100%;
            border-right: none;
            box-shadow: none;
        }
        body.panel-mode .sidebar-header {
            padding: 12px 16px;
        }
        body.panel-mode .sidebar-content {
            padding: 12px 16px;
        }
        .integration-badge {
            display: none;
            margin-top: 8px;
            padding: 6px 10px;
            border-radius: 8px;
            font-size: 0.75rem;
            font-weight: 600;
            background: rgba(34, 197, 94, 0.2);
            border: 1px solid rgba(34, 197, 94, 0.4);
            color: rgba(255, 255, 255, 0.95);
        }
        body.panel-mode .integration-badge.visible {
            display: block;
        }
        
        @media (max-width: 1024px) {
            .sidebar {
                width: 360px;
                min-width: 320px;
            }
        }
        
        @media (max-width: 768px) {
            .main-container {
                flex-direction: column;
            }
            
            .sidebar {
                width: 100%;
                height: 50vh;
                min-width: auto;
                border-right: none;
                border-bottom: 1px solid rgba(255, 255, 255, 0.1);
            }
            
            .main-content {
                height: 50vh;
            }
            
            .sidebar-header h1 {
                font-size: 1.25rem;
            }
            
            .sidebar-section {
                padding: 12px;
            }
            
            button {
                padding: 10px 16px;
                font-size: 0.9rem;
            }
            
            .signifier-label {
                flex: 0 0 100px;
            }
        }
    </style>
</head>
<body>
    <script>
        (function () {
            if (window.self !== window.top) {
                document.documentElement.classList.add('panel-mode');
                document.body.classList.add('panel-mode');
            }
            var meetingSites = [
                { pattern: /meet\.google\.com/i, name: 'Google Meet' },
                { pattern: /zoom\.us|zoom\.com/i, name: 'Zoom' },
                { pattern: /teams\.microsoft\.com|teams\.live\.com/i, name: 'Microsoft Teams' },
                { pattern: /webex\.com|\.webex\./i, name: 'Webex' },
                { pattern: /whereby\.com/i, name: 'Whereby' },
                { pattern: /gotomeeting\.com/i, name: 'GoToMeeting' },
                { pattern: /jitsi\.org|meet\.jit\.si/i, name: 'Jitsi' },
                { pattern: /discord\.com/i, name: 'Discord' },
                { pattern: /duo\.google\.com/i, name: 'Google Duo' }
            ];
            window.addEventListener('message', function (e) {
                if (e.data && e.data.type === 'TAB_URL' && typeof e.data.url === 'string') {
                    var url = e.data.url;
                    var badge = document.getElementById('integrationBadge');
                    if (!badge) return;
                    for (var i = 0; i < meetingSites.length; i++) {
                        if (meetingSites[i].pattern.test(url)) {
                            badge.textContent = 'Optimized for ' + meetingSites[i].name;
                            badge.classList.add('visible');
                            return;
                        }
                    }
                    badge.textContent = '';
                    badge.classList.remove('visible');
                }
            });
        })();
    </script>
    <div class="main-container">
        <!-- Sidebar -->
        <div class="sidebar">
            <div class="sidebar-header">
                <h1>Business Meeting Copilot</h1>
                <div class="status-indicator">
                    <p>AI-powered meeting coach with speech recognition and talking avatar.</p>
                </div>
                <div id="integrationBadge" class="integration-badge" aria-live="polite"></div>
            </div>
            
            <div class="sidebar-content">
                <!-- Controls Section -->
                <div class="sidebar-section">
                    <div class="controls-header">
                        <span class="sidebar-section-title">Controls</span>
                        <span id="sessionStatusIndicator" class="session-status session-status-idle" aria-live="polite" title="Insights session status">● Idle</span>
                    </div>
                    <div class="button-group">
                        <button id="initAvatar" onclick="initializeInsightsSession()">Start Insights Session</button>
                        <button id="selectVideoSource" onclick="promptVideoSourceSelection(true)" class="secondary" style="display: none;">Change Video Source</button>
                        <button id="stopPartnerSharing" onclick="stopPartnerSharing()" class="secondary" style="display: none;" title="Stop sharing your screen/tab for Meeting Partner Video">Stop sharing</button>
                        <button id="microphone" onclick="microphone()" disabled>Start Microphone</button>
                        <button id="stopSpeaking" onclick="stopSpeaking()" disabled>Stop Speaking</button>
                        <button id="stopSession" onclick="stopSession()" disabled class="danger">Close Insights Session</button>
                    </div>
                </div>
                
                <!-- Insight Transcript: responses from audiovisual cues (popup + TTS); verify logic here -->
                <div class="sidebar-section insight-transcript-section">
                    <div class="sidebar-section-title">Insight Transcript</div>
                    <div id="insightTranscript" class="insight-transcript-box" aria-live="polite" title="Insight responses (visual + aural cues)">No insights yet.</div>
                </div>
                
                <!-- Video Feed Section (confined to sidebar) -->
                <div class="sidebar-section video-feed-section">
                    <div class="sidebar-section-title">Video Feed</div>
                    <div id="remoteVideo" class="sidebar-video-wrap">
                        <div id="engagementFeedWrap" class="engagement-feed-wrap" style="display:none;">
                            <img id="engagementFeed" class="engagement-feed" alt="Engagement video feed" />
                        </div>
                        <div id="avatarPip" class="avatar-pip"></div>
                        <div id="subtitles" hidden></div>
                    </div>
                </div>
                
                <!-- Engagement Metrics: MediaPipe (30 signifiers) or Azure Face API (emotions + B2B composites) -->
                <div class="sidebar-section engagement-signifiers-panel">
                    <div class="sidebar-section-title engagement-metrics-title">Engagement Metrics</div>
                    <div id="engagementMetricsHint" class="engagement-metrics-hint" style="display: none;"></div>
                    <div id="signifierPanelContainer"></div>
                    <div id="azureMetricsPanelContainer" class="metrics-panel-container" style="display: none;"></div>
                </div>
            </div>
        </div>
    </div>

    <!-- Metric spike toast container (popup when a metric group spikes) -->
    <div id="metricSpikeToast" class="metric-spike-toast" style="display: none;" aria-live="polite"></div>

    <!-- Modular JavaScript Modules -->
    <script src="/static/js/signifier-panel.js"></script>
    <script src="/static/js/azure-metrics-panel.js"></script>
    <script src="/static/js/engagement-detector.js"></script>
    <script src="/static/js/session-manager.js"></script>
    <script src="/static/js/avatar-chat-manager.js"></script>
    <script src="/static/js/video-source-selector.js"></script>

    <script>
        // ========================================================================
        // Business Meeting Copilot - Main Application Script
        // ========================================================================
        // Flow: 1) Insights Session takes audio from feed (STT) -> transcript to backend
        //       2) Engagement detector takes video from feed -> visual cues (G1-G4 spikes)
        //       3) On spike: backend fuses visual + aural context -> Azure OpenAI -> insight
        //       4) Frontend: popup + Insight Transcript box + TTS (avatar)
        // ========================================================================
        // Global Variables & Configuration
        // ========================================================================
        var speechRecognizer
        var feedSpeechRecognizer = null  // STT on meeting partner (feed) audio for aural cues; transcript sent to backend
        var avatarSynthesizer
        var peerConnection
        var peerConnectionDataChannel
        var appConfig = null
        
        // Session Management (modular)
        var sessionManager = null
        var avatarChatManager = null
        var engagementDetector = null
        var signifierPanel = null
        var azureMetricsPanel = null
        var videoSourceSelector = null
        
        // UI State
        var avatarAudioInitialized = false
        var sessionActive = false
        var dataSources = []
        
        /** Update the Insights Session status pill (Idle / Live). */
        function updateSessionStatusIndicator(isLive) {
            var el = document.getElementById('sessionStatusIndicator')
            if (!el) return
            if (isLive) {
                el.textContent = '● Live'
                el.className = 'session-status session-status-live'
                el.title = 'Insights session is running'
            } else {
                el.textContent = '● Idle'
                el.className = 'session-status session-status-idle'
                el.title = 'Insights session status'
            }
        }
        var videoSourcePromptShown = false  // Track if video source prompt has been shown

        // ========================================================================
        // Metric spike alerts (popup when a metric group spikes)
        // ========================================================================
        var spikeToastTimeout = null;
        
        /**
         * Append an insight response to the sidebar transcript box (for verification).
         * @param {string} message - Insight text from Azure OpenAI
         */
        function appendToInsightTranscript(message) {
            var box = document.getElementById('insightTranscript');
            if (!box) return;
            var time = new Date().toLocaleTimeString([], { hour: '2-digit', minute: '2-digit', second: '2-digit' });
            var entry = '<div class="insight-entry"><span class="insight-time">' + time + '</span><br/>' + String(message).replace(/</g, '&lt;').replace(/>/g, '&gt;') + '</div>';
            if (box.innerHTML === 'No insights yet.' || !box.innerHTML.trim()) {
                box.innerHTML = entry;
            } else {
                box.innerHTML += entry;
            }
            box.scrollTop = box.scrollHeight;
        }
        
        /**
         * Clear the insight transcript (when session stops).
         */
        function clearInsightTranscript() {
            var box = document.getElementById('insightTranscript');
            if (box) box.innerHTML = 'No insights yet.';
        }
        
        /**
         * Handle metric spike alert: show popup, append to transcript, speak via TTS.
         * Flow: visual spike + optional aural context -> Azure OpenAI -> popup + TTS.
         */
        function handleMetricSpikeAlert(alert) {
            if (!alert || !alert.message) return;
            var msg = String(alert.message).trim();
            if (!msg) return;
            // 1. Append to sidebar transcript for verification
            appendToInsightTranscript(msg);
            // 2. Show popup toast
            var el = document.getElementById('metricSpikeToast');
            if (el) {
                if (spikeToastTimeout) clearTimeout(spikeToastTimeout);
                el.textContent = msg;
                el.style.display = 'block';
                el.classList.remove('hiding');
                spikeToastTimeout = setTimeout(function () {
                    el.classList.add('hiding');
                    spikeToastTimeout = setTimeout(function () {
                        el.style.display = 'none';
                        el.classList.remove('hiding');
                        spikeToastTimeout = null;
                    }, 220);
                }, 6000);
            }
            // 3. TTS via avatar (when session is active; speak() handles internal null checks)
            if (avatarChatManager && avatarAudioInitialized && sessionActive) {
                try {
                    avatarChatManager.interruptCurrentResponse();
                    setTimeout(function () {
                        if (sessionActive && avatarChatManager && avatarAudioInitialized) {
                            try { avatarChatManager.speak(msg); } catch (e) { console.warn('Insight TTS:', e); }
                        }
                    }, 120);
                } catch (e) {
                    console.warn('Insight TTS error:', e);
                }
            }
        }
        
        // ========================================================================
        // System Initialization
        // ========================================================================
        
        /**
         * Initialize all systems (engagement detection, session manager).
         * Insights/chat manager is initialized when insights session starts.
         */
        function initializeSystems() {
            try {
                var apiBase = getApiBase();
                // Initialize 30-metrics signifier panel (MediaPipe)
                signifierPanel = new SignifierPanel({ containerId: 'signifierPanelContainer' });
                signifierPanel.init();
                // Initialize Azure Face API metrics panel (emotions + B2B composites; shown only when Azure)
                azureMetricsPanel = new AzureMetricsPanel({ containerId: 'azureMetricsPanelContainer' });
                azureMetricsPanel.init();
                
                // Initialize engagement detector (no bar; spike alerts show popup)
                engagementDetector = new EngagementDetector({
                    signifierPanel: signifierPanel,
                    azureMetricsPanel: azureMetricsPanel,
                    apiBaseUrl: apiBase,
                    pollInterval: 200,
                    onAlert: handleMetricSpikeAlert,
                    onPartnerStreamStateChange: updateStopPartnerSharingButton
                });
                
                // Initialize session manager
                sessionManager = new SessionManager({
                    engagementDetector: engagementDetector,
                    apiBaseUrl: apiBase
                });
                
                // Initialize video source selector (same API base so Azure Face API availability check works)
                videoSourceSelector = new VideoSourceSelector({
                    onSelect: handleVideoSourceSelected,
                    onCancel: handleVideoSourceCanceled,
                    apiBaseUrl: apiBase
                });
                
                // Show "Change Video Source" button after initialization
                const changeSourceBtn = document.getElementById('selectVideoSource');
                if (changeSourceBtn) {
                    changeSourceBtn.style.display = 'inline-block';
                }
                
                console.log('Core systems initialized (engagement + session manager + video source selector)');
            } catch (error) {
                console.error('Error initializing systems:', error);
            }
        }
        
        // ========================================================================
        // Video Source Selection & Engagement Feed Display
        // ========================================================================
        
        /** API base URL: same origin when served with backend, fallback for static open. */
        function getApiBase() {
            if (typeof window !== 'undefined' && window.location && window.location.origin) {
                return window.location.origin;
            }
            return 'http://localhost:5000';
        }
        var apiBaseUrl = getApiBase();
        
        /**
         * Show the engagement detection video feed in the main display area.
         * Uses multipart/x-mixed-replace streaming for efficient frame updates (~30 FPS).
         * The backend streams JPEG frames continuously until the feed is hidden.
         */
        function showEngagementFeed() {
            var el = document.getElementById('engagementFeed');
            if (el) {
                var base = (sessionManager && sessionManager.apiBaseUrl) ? sessionManager.apiBaseUrl : apiBaseUrl;
                // Set src to streaming endpoint - browser handles multipart/x-mixed-replace automatically
                el.src = base + '/engagement/video-feed';
                el.style.display = 'block';
            }
            var wrap = document.getElementById('engagementFeedWrap');
            if (wrap) wrap.style.display = 'block';
        }
        
        /** Set the engagement metrics hint message (shown when no metrics available). */
        function setEngagementHint(message) {
            var el = document.getElementById('engagementMetricsHint');
            if (el) {
                el.textContent = message || '';
                el.style.display = message ? 'block' : 'none';
            }
        }

        /**
         * Hide the engagement feed and stop requesting frames.
         * Setting src to empty string stops the browser from requesting more frames.
         */
        function hideEngagementFeed() {
            var el = document.getElementById('engagementFeed');
            if (el) {
                el.src = ''; // Stop streaming
                el.style.display = 'none';
            }
            var wrap = document.getElementById('engagementFeedWrap');
            if (wrap) wrap.style.display = 'none';
        }
        
        /**
         * Prompt user to select video source for engagement detection.
         * 
         * @param {boolean} force - Force show even if already shown (default: false)
         */
        function promptVideoSourceSelection(force = false) {
            // Don't show if already shown (unless forced)
            if (videoSourcePromptShown && !force) {
                return;
            }
            
            if (!videoSourceSelector) {
                console.warn('Video source selector not initialized');
                // Fallback to default (stream) with auto detection if systems are ready
                if (sessionManager) {
                    sessionManager.startSession('stream', null, null)
                        .then(function () { showEngagementFeed(); })
                        .catch(err => {
                            console.warn('Could not start parallel session:', err);
                        });
                }
                return;
            }
            
            videoSourceSelector.show();
            videoSourcePromptShown = true;
        }
        
        /**
         * Handle video source selection.
         * 
         * @param {Object} selection - Selected video source options
         */
        async function handleVideoSourceSelected(selection) {
            const { sourceType, sourcePath, file } = selection;
            
            try {
                // If file is selected, upload it first
                let finalSourcePath = sourcePath;
                
                if (sourceType === 'file' && file) {
                    // Show loading indicator
                    const confirmBtn = document.querySelector('#confirmVideoSource');
                    const originalText = confirmBtn.textContent;
                    confirmBtn.textContent = 'Uploading...';
                    confirmBtn.disabled = true;
                    
                    try {
                        // Upload file to server
                        const formData = new FormData();
                        formData.append('video', file);
                        
                        const uploadResponse = await fetch(getApiBase() + '/engagement/upload-video', {
                            method: 'POST',
                            body: formData
                        });
                        
                        if (!uploadResponse.ok) {
                            const errorData = await uploadResponse.json().catch(() => ({ error: 'Upload failed' }));
                            throw new Error(errorData.error || 'Failed to upload video file');
                        }
                        
                        const uploadResult = await uploadResponse.json();
                        finalSourcePath = uploadResult.filePath;
                    } finally {
                        confirmBtn.textContent = originalText;
                        confirmBtn.disabled = false;
                    }
                }
                
                // App chooses optimal detection method (auto); no selection passed
                // Partner: getDisplayMedia must run under the same user gesture as the click.
                // Call it first (before any await), then start session and frame stream on success.
                if (sourceType === 'partner' && sessionManager && engagementDetector) {
                    let stream;
                    try {
                        // Request audio when available so partner speech can be sent to backend for insight generation
                        stream = await navigator.mediaDevices.getDisplayMedia({ video: true, audio: true });
                    } catch (shareErr) {
                        if (shareErr.name === 'NotAllowedError') {
                            console.log('Share canceled by user');
                            return;
                        }
                        console.error('Partner capture failed:', shareErr);
                        if (shareErr.name === 'NotSupportedError' || (shareErr.message && shareErr.message.indexOf('secure') !== -1)) {
                            alert('Screen share requires a secure context (localhost or HTTPS). Open the app in a secure page and try again.');
                        } else {
                            alert('Screen share failed: ' + (shareErr.message || shareErr.name || 'Unknown error'));
                        }
                        return;
                    }
                    await sessionManager.startSession('partner', null, null);
                    showEngagementFeed();
                    engagementDetector.startPartnerFrameStream(stream);
                    if (stream.getAudioTracks().length > 0) {
                        await startFeedAudioTranscript(stream);
                    }
                    console.log('Engagement detection started with Meeting Partner Video (video → engagement, audio → aural cues)');
                    return;
                }
                
                if (sessionManager) {
                    await sessionManager.startSession(sourceType, finalSourcePath, null);
                    showEngagementFeed();
                    console.log('Engagement detection started with source: ' + sourceType);
                }
            } catch (error) {
                console.error('Error starting engagement detection with selected source:', error);
                alert(`Failed to start engagement detection: ${error.message}\n\nPlease try again or select a different source.`);
            }
        }
        
        /**
         * Show or hide the "Stop sharing" button based on partner stream state.
         * When partner stream ends, also stop feed-audio transcript (aural cues).
         * @param {boolean} isActive - Whether Meeting Partner Video capture is active
         */
        function updateStopPartnerSharingButton(isActive) {
            var btn = document.getElementById('stopPartnerSharing');
            if (btn) btn.style.display = isActive ? 'inline-block' : 'none';
            if (!isActive) stopFeedAudioTranscript();
        }
        
        /**
         * Stop sharing screen/tab for Meeting Partner Video (stops getDisplayMedia and frame sending).
         */
        function stopPartnerSharing() {
            if (engagementDetector && engagementDetector.isPartnerStreamActive()) {
                engagementDetector.stopPartnerFrameStream();
            }
            stopFeedAudioTranscript();
        }
        
        /**
         * Start speech recognition on the meeting partner (feed) audio stream.
         * Recognized text is sent to POST /engagement/transcript for B2B insight generation (aural cues).
         * Runs in parallel with engagement detector (video cues). Use when source is 'partner' and stream has audio.
         * @param {MediaStream} stream - getDisplayMedia stream with audio track (meeting partner)
         */
        async function startFeedAudioTranscript(stream) {
            if (!stream || stream.getAudioTracks().length === 0) return;
            stopFeedAudioTranscript();
            if (!appConfig) await loadConfig();
            if (!appConfig) {
                console.warn('Feed audio transcript: config not loaded, skipping.');
                return;
            }
            try {
                const tokenRes = await fetch(getApiBase() + '/speech/token');
                if (!tokenRes.ok) {
                    console.warn('Feed audio transcript: failed to get speech token.');
                    return;
                }
                const { token } = await tokenRes.json();
                const cogSvcRegion = appConfig.speech.region;
                const privateEndpointEnabled = appConfig.speech.privateEndpointEnabled || false;
                let speechRecognitionConfig;
                if (privateEndpointEnabled) {
                    const privateEndpoint = appConfig.speech.privateEndpoint || '';
                    speechRecognitionConfig = SpeechSDK.SpeechConfig.fromEndpoint(
                        new URL('wss://' + privateEndpoint + '/stt/speech/universal/v2'),
                        token
                    );
                } else {
                    speechRecognitionConfig = SpeechSDK.SpeechConfig.fromAuthorizationToken(token, cogSvcRegion);
                }
                speechRecognitionConfig.setProperty(SpeechSDK.PropertyId.SpeechServiceConnection_LanguageIdMode, 'Continuous');
                var sttLocales = (appConfig.sttTts && appConfig.sttTts.sttLocales) ? appConfig.sttTts.sttLocales.split(',') : ['en-US'];
                var autoDetectSourceLanguageConfig = SpeechSDK.AutoDetectSourceLanguageConfig.fromLanguages(sttLocales);
                var audioConfig = SpeechSDK.AudioConfig.fromStreamInput(stream);
                feedSpeechRecognizer = SpeechSDK.SpeechRecognizer.FromConfig(
                    speechRecognitionConfig,
                    autoDetectSourceLanguageConfig,
                    audioConfig
                );
                feedSpeechRecognizer.recognized = function (s, e) {
                    if (e.result.reason !== SpeechSDK.ResultReason.RecognizedSpeech) return;
                    var text = (e.result.text || '').trim();
                    if (!text) return;
                    fetch(getApiBase() + '/engagement/transcript', {
                        method: 'POST',
                        headers: { 'Content-Type': 'application/json' },
                        body: JSON.stringify({ text: text })
                    }).catch(function (err) { console.warn('Feed transcript POST failed:', err); });
                };
                feedSpeechRecognizer.startContinuousRecognitionAsync(
                    function () { console.log('Feed audio (aural cues) transcript started.'); },
                    function (err) { console.warn('Feed audio transcript start failed:', err); feedSpeechRecognizer = null; }
                );
            } catch (err) {
                console.warn('Start feed audio transcript failed:', err);
                feedSpeechRecognizer = null;
            }
        }
        
        /**
         * Stop speech recognition on feed audio and release recognizer.
         */
        function stopFeedAudioTranscript() {
            if (!feedSpeechRecognizer) return;
            try {
                feedSpeechRecognizer.stopContinuousRecognitionAsync(function () {}, function () {});
                feedSpeechRecognizer.close();
            } catch (e) {}
            feedSpeechRecognizer = null;
        }
        
        /**
         * Handle video source selection cancellation.
         */
        function handleVideoSourceCanceled() {
            console.log('Video source selection canceled');
            videoSourcePromptShown = true;
            // Ensure engagement is running (e.g. if auto-start failed)
            if (sessionManager && engagementDetector && !engagementDetector.isActive) {
                sessionManager.startSession('webcam', null, null)
                    .then(function (ok) { if (ok) showEngagementFeed(); })
                    .catch(function (err) { console.warn('Could not start engagement with webcam:', err); });
            }
        }

        // Configuration from backend
        async function loadConfig() {
            try {
                const response = await fetch(getApiBase() + '/config/all');
                if (!response.ok) throw new Error('Failed to fetch config: ' + response.status);
                appConfig = await response.json();
                console.log('Configuration loaded from backend', appConfig);
            } catch (error) {
                console.error('Failed to load configuration:', error);
                alert('Failed to load configuration from backend. Please ensure the server is running.');
            }
        }

        /**
         * Start Insights Session (audio-only).
         * Pairs speech cues (from meeting partner audio when available) with visual cues
         * (engagement detector) for real-time actionable insights. Popup messages are
         * generated by Azure OpenAI when a moment is detected (e.g. spike in interest,
         * confusion, resistance, or decision-ready). See docs/DOCUMENTATION.md.
         */
        async function initializeInsightsSession() {
            if (!appConfig) {
                await loadConfig()
            }
            
            if (!appConfig) {
                alert('Failed to load configuration. Please refresh the page.')
                return
            }

            const cogSvcRegion = appConfig.speech.region
            const privateEndpointEnabled = appConfig.speech.privateEndpointEnabled || false

            // Get speech token from backend
            const tokenRes = await fetch(getApiBase() + '/speech/token')
            if (!tokenRes.ok) {
                alert('Failed to get speech token from backend.')
                return
            }
            const { token } = await tokenRes.json()

            // Initialize Avatar Synthesizer for TTS
            let speechSynthesisConfig
            const isCustomAvatar = appConfig.avatar.customized
            const isCustomVoice = appConfig.sttTts.customVoiceEndpointId && appConfig.sttTts.customVoiceEndpointId !== ''
            
            if (privateEndpointEnabled) {
                const privateEndpoint = appConfig.speech.privateEndpoint || ''
                let endpoint_route = isCustomAvatar || isCustomVoice ? 'voice' : 'tts'
                speechSynthesisConfig = SpeechSDK.SpeechConfig.fromEndpoint(
                    new URL(`wss://${privateEndpoint}/${endpoint_route}/cognitiveservices/websocket/v1?enableTalkingAvatar=true`),
                    token
                )
            } else {
                speechSynthesisConfig = SpeechSDK.SpeechConfig.fromAuthorizationToken(token, cogSvcRegion)
            }
            speechSynthesisConfig.endpointId = appConfig.sttTts.customVoiceEndpointId || ''

            const talkingAvatarCharacter = appConfig.avatar.character
            const talkingAvatarStyle = appConfig.avatar.style
            const avatarConfig = new SpeechSDK.AvatarConfig(talkingAvatarCharacter, talkingAvatarStyle)
            avatarConfig.photoAvatarBaseModel = appConfig.avatar.photoAvatar ? 'vasa-1' : ''
            avatarConfig.customized = appConfig.avatar.customized
            avatarConfig.useBuiltInVoice = appConfig.avatar.useBuiltInVoice
            avatarSynthesizer = new SpeechSDK.AvatarSynthesizer(speechSynthesisConfig, avatarConfig)
            
            avatarSynthesizer.avatarEventReceived = function (s, e) {
                var offsetMessage = ", offset from session start: " + e.offset / 10000 + "ms."
                if (e.offset === 0) {
                    offsetMessage = ""
                }
                console.log("Avatar event received: " + e.description + offsetMessage)
            }

            // Initialize Speech Recognizer for STT
            let speechRecognitionConfig
            if (privateEndpointEnabled) {
                const privateEndpoint = appConfig.speech.privateEndpoint || ''
                speechRecognitionConfig = SpeechSDK.SpeechConfig.fromEndpoint(
                    new URL(`wss://${privateEndpoint}/stt/speech/universal/v2`),
                    token
                )
            } else {
                speechRecognitionConfig = SpeechSDK.SpeechConfig.fromAuthorizationToken(token, cogSvcRegion)
            }
            speechRecognitionConfig.setProperty(SpeechSDK.PropertyId.SpeechServiceConnection_LanguageIdMode, "Continuous")
            var sttLocales = appConfig.sttTts.sttLocales.split(',')
            var autoDetectSourceLanguageConfig = SpeechSDK.AutoDetectSourceLanguageConfig.fromLanguages(sttLocales)
            speechRecognizer = SpeechSDK.SpeechRecognizer.FromConfig(
                speechRecognitionConfig,
                autoDetectSourceLanguageConfig,
                SpeechSDK.AudioConfig.fromDefaultMicrophoneInput()
            )

            // Initialize messages
            // Messages are initialized by avatarChatManager when ready
            // Fallback initialization if chat manager not ready yet
            if (!avatarChatManager && appConfig) {
                initMessages();
            }

            // Get relay token and set up WebRTC for insight audio (audio-only; no avatar video)
            const relayRes = await fetch(getApiBase() + '/avatar/relay-token')
            if (!relayRes.ok) {
                alert('Failed to get relay token from backend.')
                return
            }
            const relayData = await relayRes.json()
            const iceServerUrl = relayData.Urls[0]
            const iceServerUsername = relayData.Username
            const iceServerCredential = relayData.Password
            setupWebRTCForAudio(iceServerUrl, iceServerUsername, iceServerCredential)
        }

        /**
         * Setup WebRTC for insight playback (audio-only).
         * Audio track is used for TTS when insights are spoken; video track is not shown
         * so the session is audio-only from the user's perspective.
         */
        function setupWebRTCForAudio(iceServerUrl, iceServerUsername, iceServerCredential) {
            peerConnection = new RTCPeerConnection({
                iceServers: [{
                    urls: [iceServerUrl],
                    username: iceServerUsername,
                    credential: iceServerCredential
                }]
            })

            // Audio-only: use audio track for insight TTS; do not show avatar video
            var avatarContainer = function () { return document.getElementById('avatarPip'); };
            peerConnection.ontrack = function (event) {
                if (event.track.kind === 'audio') {
                    let audioElement = document.createElement('audio')
                    audioElement.id = 'audioPlayer'
                    audioElement.srcObject = event.streams[0]
                    audioElement.autoplay = false
                    audioElement.addEventListener('loadeddata', () => {
                        audioElement.play()
                    })
                    audioElement.onplaying = () => {
                        console.log('Insights session: audio channel connected.')
                        avatarAudioInitialized = true
                        sessionActive = true
                        updateSessionStatusIndicator(true)
                        document.getElementById('initAvatar').disabled = true
                        document.getElementById('microphone').disabled = false
                        document.getElementById('stopSession').disabled = false
                        var msgInput = document.getElementById('userMessageInput');
                        var sendBtn = document.getElementById('sendMessageBtn');
                        if (msgInput) msgInput.disabled = false;
                        if (sendBtn) sendBtn.disabled = false;
                        if (msgInput) msgInput.focus();
                        if (sessionManager) {
                            sessionManager.isAvatarInitialized = true;
                        }
                        if (!videoSourcePromptShown && videoSourceSelector) {
                            promptVideoSourceSelection();
                        }
                    }
                    var pip = avatarContainer()
                    if (pip) {
                        var existing = pip.querySelector('audio')
                        if (existing) existing.remove()
                        pip.appendChild(audioElement)
                    }
                }
                // Video track: do not add to DOM (audio-only session)
                if (event.track.kind === 'video') {
                    event.track.enabled = false
                }
            }

            // Handle data channel for avatar events (subtitles, etc.)
            peerConnection.addEventListener("datachannel", event => {
                peerConnectionDataChannel = event.channel
            peerConnectionDataChannel.onmessage = e => {
                try {
                    const webRTCEvent = JSON.parse(e.data)
                    const subtitles = document.getElementById('subtitles')
                    if (!subtitles) return
                    if (webRTCEvent.event.eventType === 'EVENT_TYPE_TURN_START' && appConfig && appConfig.avatar && appConfig.avatar.showSubtitles) {
                        subtitles.hidden = false
                        if (avatarChatManager && avatarChatManager.speakingText) {
                            subtitles.innerHTML = avatarChatManager.speakingText
                        }
                    } else if (webRTCEvent.event.eventType === 'EVENT_TYPE_SESSION_END' || webRTCEvent.event.eventType === 'EVENT_TYPE_SWITCH_TO_IDLE') {
                        subtitles.hidden = true
                    }
                    console.log("[" + (new Date()).toISOString() + "] WebRTC event: " + e.data)
                } catch (err) { console.debug('WebRTC datachannel parse:', err) }
            }
            })

            // Create data channel for events
            let c = peerConnection.createDataChannel("eventChannel")

            peerConnection.oniceconnectionstatechange = e => {
                console.log("WebRTC status: " + peerConnection.iceConnectionState)
            }

            // Video: recvonly so we only receive the avatar stream—avoids requesting the user's
            // camera and prevents conflict with engagement detection (backend cv2.VideoCapture).
            // Audio: sendrecv for user mic → avatar and avatar → user.
            peerConnection.addTransceiver('video', { direction: 'recvonly' })
            peerConnection.addTransceiver('audio', { direction: 'sendrecv' })

            // Start avatar synthesizer
            avatarSynthesizer.startAvatarAsync(peerConnection).then((r) => {
                if (r.reason === SpeechSDK.ResultReason.SynthesizingAudioCompleted) {
                    console.log("[" + (new Date()).toISOString() + "] Avatar started. Result ID: " + r.resultId)
                    
                    // Initialize avatar chat manager now that avatar is ready
                    if (sessionManager && !avatarChatManager) {
                        avatarChatManager = new AvatarChatManager({
                            sessionManager: sessionManager,
                            avatarSynthesizer: avatarSynthesizer,
                            appConfig: appConfig
                        });
                        console.log('Avatar chat manager initialized');
                    }
                    if (sessionManager) {
                        sessionManager.isAvatarInitialized = true;
                    }
                    avatarAudioInitialized = true;
                    sessionActive = true;
                    updateSessionStatusIndicator(true);
                } else {
                    console.log("[" + (new Date()).toISOString() + "] Unable to start avatar. Result ID: " + r.resultId)
                    if (r.reason === SpeechSDK.ResultReason.Canceled) {
                        let cancellationDetails = SpeechSDK.CancellationDetails.fromResult(r)
                        if (cancellationDetails.reason === SpeechSDK.CancellationReason.Error) {
                            console.log(cancellationDetails.errorDetails)
                        }
                        console.log("Unable to start avatar: " + cancellationDetails.errorDetails)
                    }
                    document.getElementById('initAvatar').disabled = false
                    updateSessionStatusIndicator(false)
                }
            }).catch((error) => {
                console.log("[" + (new Date()).toISOString() + "] Avatar failed to start. Error: " + error)
                alert("Failed to start insights session: " + error)
                document.getElementById('initAvatar').disabled = false
                updateSessionStatusIndicator(false)
            })
        }
        
        // ========================================================================
        // Session Management
        // ========================================================================
        
        /**
         * Stop insights session and clean up all resources.
         */
        async function stopSession() {
            // Stop parallel session (engagement detection + chat)
            if (sessionManager) {
                await sessionManager.stopSession();
            }
            stopFeedAudioTranscript();

            try {
                if (avatarSynthesizer) avatarSynthesizer.close();
            } catch (e) { console.debug('Avatar close:', e); }

            try {
                if (speechRecognizer) {
                    speechRecognizer.stopContinuousRecognitionAsync(function () {}, function () {});
                    speechRecognizer.close();
                }
            } catch (e) { console.debug('Speech recognizer close:', e); }

            try {
                if (peerConnection) peerConnection.close();
            } catch (e) { console.debug('PeerConnection close:', e); }
            
            // Update state
            sessionActive = false;
            avatarAudioInitialized = false;
            updateSessionStatusIndicator(false);
            clearInsightTranscript();
            
            // Stop engagement feed and clear avatar PIP (keep layout structure)
            hideEngagementFeed();
            let avatarPipEl = document.getElementById('avatarPip');
            if (avatarPipEl) avatarPipEl.innerHTML = '';
            
            // Update UI
            var initBtn = document.getElementById('initAvatar');
            var micBtn = document.getElementById('microphone');
            var stopBtn = document.getElementById('stopSession');
            var speakBtn = document.getElementById('stopSpeaking');
            if (initBtn) initBtn.disabled = false;
            if (micBtn) micBtn.disabled = true;
            if (stopBtn) stopBtn.disabled = true;
            if (speakBtn) speakBtn.disabled = true;
            var msgInput = document.getElementById('userMessageInput');
            var sendBtn = document.getElementById('sendMessageBtn');
            if (msgInput) { msgInput.disabled = true; msgInput.value = ''; }
            if (sendBtn) sendBtn.disabled = true;
        }

        // HTML encoding
        function htmlEncode(text) {
            const entityMap = {
                '&': '&amp;',
                '<': '&lt;',
                '>': '&gt;',
                '"': '&quot;',
                "'": '&#39;',
                '/': '&#x2F;'
            }
            return String(text).replace(/[&<>"'\/]/g, (match) => entityMap[match])
        }

        // ========================================================================
        // Message Management
        // ========================================================================
        
        /**
         * Initialize messages array.
         */
        function initMessages() {
            if (avatarChatManager) {
                avatarChatManager.initMessages();
            }
            
            // Initialize data sources for cognitive search
            if (!appConfig) {
                console.error('Configuration not loaded');
                return;
            }
            
            if (appConfig.cognitiveSearch && appConfig.cognitiveSearch.enabled) {
                dataSources = [{
                    type: 'AzureCognitiveSearch',
                    parameters: {
                        endpoint: appConfig.cognitiveSearch.endpoint,
                        key: appConfig.cognitiveSearch.apiKey,
                        indexName: appConfig.cognitiveSearch.indexName,
                        semanticConfiguration: '',
                        queryType: 'simple',
                        fieldsMapping: {
                            contentFieldsSeparator: '\n',
                            contentFields: ['content'],
                            filepathField: null,
                            titleField: 'title',
                            urlField: null
                        },
                        inScope: true,
                        roleInformation: appConfig.systemPrompt
                    }
                }];
            } else {
                dataSources = [];
            }
        }
        
        /**
         * Clear chat history.
         */
        function clearChatHistory() {
            if (avatarChatManager) {
                avatarChatManager.clearChatHistory();
            }
            initMessages();
        }

        // ========================================================================
        // Speech Functions (Delegated to AvatarChatManager)
        // ========================================================================
        
        // ========================================================================
        // Speech Functions (Delegated to AvatarChatManager)
        // ========================================================================
        
        // ========================================================================
        // Speech Functions (Delegated to AvatarChatManager)
        // ========================================================================
        
        /**
         * Speak text - delegates to AvatarChatManager.
         * Kept for backward compatibility with existing code.
         */
        function speak(text, endingSilenceMs = 0) {
            if (avatarChatManager) {
                avatarChatManager.speak(text, endingSilenceMs);
            }
        }
        
        /**
         * Stop speaking - delegates to AvatarChatManager.
         * Kept for backward compatibility with existing code.
         */
        function stopSpeaking() {
            if (avatarChatManager) {
                avatarChatManager.stopSpeaking();
            }
        }
        
        // Expose isSpeaking for UI updates (delegates to AvatarChatManager)
        // This allows existing code that checks isSpeaking to continue working
        Object.defineProperty(window, 'isSpeaking', {
            get: function() {
                return avatarChatManager ? avatarChatManager.isSpeaking : false;
            },
            configurable: true
        });

        // ========================================================================
        // Chat Handling (Streamlined)
        // ========================================================================
        
        /**
         * Handle user query - streamlined version using AvatarChatManager.
         * 
         * @param {string} userQuery - User's message
         * @param {string} userQueryHTML - HTML formatted user query
         * @param {string} imgUrlPath - Optional image URL path
         */
        async function handleUserQuery(userQuery, userQueryHTML, imgUrlPath) {
            if (!avatarChatManager) {
                console.error('Avatar chat manager not initialized');
                return;
            }
            
            await avatarChatManager.handleUserQuery(userQuery, userQueryHTML, imgUrlPath);
        }


        function microphone() {
            if (!speechRecognizer || !avatarAudioInitialized || !sessionActive) {
                alert('Please start insights session first, then start microphone.')
                return
            }

            if (document.getElementById('microphone').innerHTML === 'Stop Microphone') {
                document.getElementById('microphone').disabled = true
                speechRecognizer.stopContinuousRecognitionAsync(() => {
                    document.getElementById('microphone').innerHTML = 'Start Microphone'
                    document.getElementById('microphone').disabled = false
                }, (err) => {
                    console.log("Failed to stop continuous recognition:", err)
                    document.getElementById('microphone').disabled = false
                })
                return
            }

            document.getElementById('microphone').disabled = true

            // Pause avatar as soon as user starts speaking (interim results)
            speechRecognizer.recognizing = (s, e) => {
                if (e.result.reason !== SpeechSDK.ResultReason.RecognizingSpeech) return;
                const partial = (e.result.text || '').trim();
                if (partial.length < 2) return;
                if (avatarChatManager && (avatarChatManager.isSpeaking || (avatarChatManager.sessionManager && avatarChatManager.sessionManager.isStreaming))) {
                    avatarChatManager.interruptCurrentResponse();
                }
            };

            speechRecognizer.recognized = async (s, e) => {
                if (e.result.reason === SpeechSDK.ResultReason.RecognizedSpeech) {
                    let userQuery = e.result.text.trim()
                    if (userQuery === '') {
                        return
                    }

                    // Interrupt avatar chat if still speaking/streaming (in case recognizing didn't fire)
                    if (avatarChatManager) {
                        avatarChatManager.interruptCurrentResponse();
                        await new Promise(resolve => setTimeout(resolve, 100));
                    }

                    if (!appConfig || !appConfig.sttTts || !appConfig.sttTts.continuousConversation) {
                        document.getElementById('microphone').disabled = true
                        speechRecognizer.stopContinuousRecognitionAsync(() => {
                            document.getElementById('microphone').innerHTML = 'Start Microphone'
                            document.getElementById('microphone').disabled = false
                        }, (err) => {
                            console.log("Failed to stop continuous recognition:", err)
                            document.getElementById('microphone').disabled = false
                        })
                    }

                    handleUserQuery(userQuery, "", "")
                }
            }

            speechRecognizer.startContinuousRecognitionAsync(() => {
                document.getElementById('microphone').innerHTML = 'Stop Microphone'
                document.getElementById('microphone').disabled = false
            }, (err) => {
                console.log("Failed to start continuous recognition:", err)
                document.getElementById('microphone').disabled = false
            })
        }

        // Message sending functions
        function handleMessageKeyPress(event) {
            if (event.key === 'Enter' && !event.shiftKey) {
                event.preventDefault()
                sendMessage()
            }
        }
        
        async function sendMessage() {
            const input = document.getElementById('userMessageInput');
            const sendBtn = document.getElementById('sendMessageBtn');
            if (!input) return;
            const message = (input.value || '').trim();
            
            if (!message) {
                return
            }
            
            if (!appConfig) {
                alert('Configuration not loaded. Please refresh the page.')
                return
            }
            
            if (!avatarAudioInitialized || !sessionActive) {
                alert('Please start insights session first.')
                return
            }
            
            // Interrupt avatar chat if speaking
            if (avatarChatManager) {
                avatarChatManager.interruptCurrentResponse();
                await new Promise(resolve => setTimeout(resolve, 100));
            }
            
            // Disable input and button while processing
            input.disabled = true
            sendBtn.disabled = true
            
            // Clear input immediately for better UX
            input.value = ''
            
            // Send the message
            handleUserQuery(message, message, "")
            
            // Re-enable input and button after a brief moment
            setTimeout(() => {
                input.disabled = false
                sendBtn.disabled = false
                input.focus()
            }, 300)
        }

        // ========================================================================
        // Initialization
        // ========================================================================
        
        // Initialize systems and auto-start engagement with webcam so metrics work immediately.
        function onSystemsReady() {
            initializeSystems();
            // Auto-start engagement with webcam so metrics populate without requiring modal interaction
            if (sessionManager) {
                sessionManager.startSession('webcam', null, null)
                    .then(function (ok) {
                        if (ok) {
                            showEngagementFeed();
                            console.log('Engagement detection auto-started with webcam');
                        } else {
                            setEngagementHint('Could not start. Click Change Video Source to retry.');
                        }
                    })
                    .catch(function (err) {
                        console.warn('Engagement auto-start error:', err);
                        setEngagementHint('Could not connect. Ensure the server is running and click Change Video Source to retry.');
                    });
            }
            // Modal available via "Change Video Source" button; no auto-popup on load
        }
        if (document.readyState === 'loading') {
            document.addEventListener('DOMContentLoaded', onSystemsReady);
        } else {
            onSystemsReady();
        }

        window.onload = () => {
            loadConfig().then(() => {
                if (avatarChatManager) {
                    avatarChatManager.initMessages();
                } else {
                    initMessages();
                }
            });
            if (!sessionManager || !engagementDetector) {
                onSystemsReady();
            }
        }
    </script>
</body>
</html>
